```
и какого черта этого не было на лекциях?
```

## ковариационная матрица случайного вектора
[предлагаю почитать википедию.](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0#:~:text=%D0%9A%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F%20%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0%20%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0%20%E2%80%94%20%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BD%D0%B0%D1%8F,%D0%B2%D0%BD%D0%B5%D0%B4%D0%B8%D0%B0%D0%B3%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%8D%D0%BB%D0%B5%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%E2%80%94%20%D0%BA%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%B8%20%D0%BC%D0%B5%D0%B6%D0%B4%D1%83%20%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82%D0%B0%D0%BC%D0%B8.)

==$\aleph$== ковариационная матрица (или матрица ковариаций) — это матрица, составленная из попарных ковариаций элементов одного или двух случайных векторов.

ковариационная матрица случайного вектора — квадратная симметрическая неотрицательно определенная матрица, на диагонали которой располагаются дисперсии компонент вектора, а внедиагональные элементы — ковариации между компонентами.

дана многомерная случайная величина $(\xi_1,\ ...,\ \xi_n)$.
$$cov(\xi_i,\ \xi_j) = M[(\xi_i - M(\xi_i))(\xi_j - M(\xi_j))]$$
составим матрицу из ковариаций:

$$k = \left(\begin{array}{c}
cov(\xi_1,\ \xi_1) & cov(\xi_1,\ \xi_2) & ... & cov(\xi_1,\ \xi_n) \\
cov(\xi_2,\ \xi_1) & cov(\xi_2,\ \xi_2) & ... & cov(\xi_2,\ \xi_n) \\
... & ... & ... & ... \\
cov(\xi_n,\ \xi_1) & cov(\xi_n,\ \xi_2) & ... & cov(\xi_n,\ \xi_n) \\
\end{array}\right)$$
зачем это надо? никто не знает.

![[вложения/15-1.png]]
![[вложения/15-2.png]]

## корреляционная матрица случайного вектора

$$\rho = \dfrac{cov(\xi_i,\ \xi_j)}{\sigma_i \sigma_j}$$

корреляционная матрица:

$$r = \left(\begin{array}{c}
1 & \rho(\xi_1,\ \xi_2) & ... & \rho(\xi_1,\ \xi_n) \\
\rho(\xi_2,\ \xi_1) & 1 & ... & \rho(\xi_2,\ \xi_n) \\
... & ... & ... & ... \\
\rho(\xi_n,\ \xi_1) & \rho(\xi_n,\ \xi_2) & ... & 1 \\
\end{array}\right)$$

единицы на главной диагонали, потому что $\rho(\xi_i,\ \xi_i) = \dfrac{cov(\xi_i,\ \xi_i)}{\sigma_i \sigma_i} =$ ну там надо пораскладывать, получить из матожидания дисперсию, из дисперсии $\sigma$, и тогда получится $=\dfrac{\sigma_i \sigma_i}{\sigma_i \sigma_i} = 1$
```
извините, я хочу спать. ;-;
```