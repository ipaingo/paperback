# № 1.1
![[матстат 1.jpg|940]]

# № 2.1
![[матстат 2.jpg|940]]

# № 3.2
ноутбук colab: https://colab.research.google.com/drive/1zNVAJ6RLzIYrsBqABYtzh7pYUqy_v3E4?usp=sharing

Сгенерируйте 200 выборок размера 500 из Exp(1). Посчитайте для каждой выборки статистику Колмогорова. Нарисуйте гистограмму по полученному набору статистик. На нем же изобразите график теоретической плотности распределения Колмогорова. Согласуется ли результат с теорией?

```python
import numpy as np
from scipy.stats import kstest, expon
import matplotlib.pyplot as plt
  
# параметры
n = 200 # число выборок
sample_size = 500 # размер каждой выборки
  
# массив с выборками
samples = np.random.exponential(scale=1, size=(n, sample_size))
  
# массив со статистиками Колмогорова
ks_stats = []

# считаем статистики
for sample in samples:
    stat, p_value = kstest(sample, 'expon', args=(0,1))
    ks_stats.append(stat)
  
ks_stats = np.array(ks_stats)
  
# одновыборочный ks-тест для проверки согласия с теорией
  
from scipy.stats import kstest, kstwobign # распределение Колмогорова
  
print("KS-тест для проверки согласия с теоретическим распределением:")
  
ks_stat, ks_pvalue = kstest(
    ks_stats,
    lambda x: kstwobign.cdf(x * np.sqrt(sample_size))
)
  
print("KS-статистика: ", ks_stat)
print("p-value: ", ks_pvalue)
  
if ks_pvalue > 0.05:
  print("Гипотезу можно принять - распределение согласуется с теоретическим")
else:
  print("Гипотезу следует отвергнуть - распределение не согласуется с теоретическим")
  
plt.figure(figsize=(14, 10))
  
# график - гистограмма с плотностью
x_values = np.linspace(min(ks_stats), max(ks_stats), 200)
kstwobign_pdf = kstwobign.pdf(x_values * np.sqrt(sample_size)) * np.sqrt(sample_size)
  
plt.hist(ks_stats, bins=20, density=True, edgecolor='black', alpha=0.5, label='Эмпирическая гистограмма')
plt.plot(x_values, kstwobign_pdf, 'r-', lw=2, label='Теоретическая плотность')
plt.xlabel('Статистика Колмогорова D_n', fontsize=11)
plt.ylabel('Плотность', fontsize=11)
plt.title('Распределение статистики Колмогорова', fontsize=11)
plt.legend(fontsize=11)
plt.grid(axis='y', linestyle='--', alpha=0.5)
  
plt.show()
```

## Результат
```
KS-тест для проверки согласия с теоретическим распределением:
KS-статистика: 0.04529923507533962
p-value: 0.7889880982071726
Гипотезу можно принять - распределение согласуется с теоретическим
```
![[Pasted image 20251116043902.png]]

## Вывод
Получившаяся гистограмма наглядно показывает, что сгенерированный результат хорошо совпадает с теоретическим распределением. Это также подтверждается KS-тестом: получилось довольно большое значение p-value, а значит, эмпирические данные действительно хорошо совпадают с теоретическим распределением. Небольшие отклонения (выходы столбцов и выбросы в правом хвосте) обоснованы случайными вариациями и небольшим объемом выборки.

Конечно, если позапускать случайную генерацию много раз, результаты могут получиться разными - иногда появляются заметные выбросы, которые визуально сильно выбиваются из графика, а KS-тест показывает, что распределение не совпало, но это в целом ожидаемо из-за случайной генерации и небольшого объема выборки.

---

# № 4.1
Из загруженного набора акций с 2014 года по конец 2022 года возьмите нужную по счету акцию в файле, соответствующую номеру этой задачи, и для нее по close values посчитайте 5-дневный 5-% VaR логарифмической доходности (по выборке). На тестовой части выборки (2023 год) проведите бэктестинг оцененного VaR одним из частотных тестов.

1-й вариант - AAPL

```python
import pandas as pd
import numpy as np
from scipy.stats import chi2, chi2_contingency
import matplotlib.pyplot as plt
  
# загружаем данные
df  = pd.read_csv('data.csv')
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')
ticker = 'AAPL'
  
# разделяем train/test
train = df[df['Date'] < '2023-01-01'].copy()
test = df[(df['Date'] >= '2023-01-01') & (df['Date'] < '2024-01-01')].copy()
  
# лог-доходности будем разбивать на блоки по 5 дней
size = 5
  
# тренировочные данные
train_prices = train[ticker].values
train_dates = train['Date'].values
train_logreturns = np.log(train_prices[1:] / train_prices[:-1])
n_train_blocks = len(train_logreturns) // size
  
train_block_logreturn = [
    train_logreturns[i * size: (i+1) * size].sum() for i in range(n_train_blocks)
]
train_block_ends = [
    train_dates[(i + 1) * size] for i in range(n_train_blocks)
]
  
# тестовые данные
test_prices = test[ticker].values
test_dates = test['Date'].values
test_logreturns = np.log(test_prices[1:] / test_prices[:-1])
n_test_blocks = len(test_logreturns) // size
  
test_block_logreturn = [
    test_logreturns[i * size: (i+1) * size].sum() for i in range(n_test_blocks)
]
test_block_ends = [
    test_dates[(i + 1) * size] for i in range(n_test_blocks)
]
  
# расчет VaR 5% (квантиль по train)
var_5p_5d = np.quantile(train_block_logreturn, 0.05)
print("5-дневный VaR 5% по блочным лог-доходностям (тренировочные данные): ", var_5p_5d)
  
# проверяем нарушения VaR на тестовых данных

# exs = np.array([float(y) for y in test_block_logreturn])
# print(exs)
  
exc = np.array([int(x < var_5p_5d) for x in test_block_logreturn])
n = len(exc)
x = exc.sum() # исключения
alpha = 0.05 # целевая частота исключений
```
```python
# бэктест методом Купика (пропорциональный тест, POF)
if 0 < x < n:
  pi_hat = x / n
  # LR-статистика Купика
  lr = -2 * ((x*np.log(alpha) + (n - x) * np.log(1 - alpha)) -
   (x * np.log(pi_hat) + (n - x) * np.log(1 - pi_hat)))
  p_value = 1 - chi2.cdf(lr, df=1)
else:
  lr = np.False_p_value = np.nan
  
print()
print('-------------------------------------------------')
print("Бэктестинг VaR на тестовых данных:")
print()
print("Ожидаемых нарушений VaR (n * alpha): ", n * alpha)
print("Фактических нарушений VaR (x): ", x)
print("p_value: ", p_value)
  
if p_value > 0.05:
  print("p_value > 0.05, нет оснований отвергать правильность VaR")
else:
  print("p_value < 0.05, VaR отвергается, частота нарушений не совпадает с теоретической")
  
# график train (тренировочные данные и VaR)
plt.figure(figsize=(12, 6))
plt.plot(train_block_ends, train_block_logreturn, linestyle='-',
         label='Тренировочные данные в 5-дневных блоках')
plt.axhline(var_5p_5d, color='red', linestyle='--', label='VaR 5% train')
plt.title('5-дневные блочные лог-доходости и VaR (тренировочные данные)')
plt.xlabel('Даты')
plt.ylabel('Лог-доходность за 5 дней')
plt.legend()
plt.tight_layout()
plt.show
  
# график test (тестовые данные и нарушения VaR)
plt.figure(figsize=(12, 4))
plt.plot(test_block_ends, test_block_logreturn, marker='o',
         label='Тестовые данные в 5-дневных блоках')
plt.axhline(var_5p_5d, color='red', linestyle='--', label='VaR 5% test')
plt.scatter([test_block_ends[i] for i in range(n) if exc[i] == 1],
 [test_block_logreturn[i] for i in range (n) if exc[i] == 1],
 color='red', zorder=5, label='Нарушения VaR')
plt.title('Нарушения VaR 5% по блокам (тестовые данные)')
plt.xlabel('Даты')
plt.ylabel('Лог-доходность за 5 дней')
plt.legend()
plt.tight_layout()
plt.show
```

## Результат
```
5-дневный VaR 5% по блочным лог-доходностям (тренировочные данные): -0.055315535814685804

-------------------------------------------------
Бэктестинг VaR на тестовых данных:

Ожидаемых нарушений VaR (n * alpha): 2.45
Фактических нарушений VaR (x): 1
p_value: 0.283020441561747
p_value > 0.05, нет оснований отвергать правильность VaR
```
![[Pasted image 20251116044017.png]]
![[Pasted image 20251116044030.png]]

## Вывод
5-дневный VaR 5% = -0.05531553. За 5 дней лог-доходность акции не упадет ниже -5,53%.
Нарушений: 1 из 49. Ожидаемое кол-во - 49 $\cdot$ 0,05 = 2,45.

Достаточно большое p-value и маленькое количество нарушений VaR (1 < 2,45) показывают, что VaR рассчитан верно. Одно значение было довольно близко к VaR: -0.05526984, когда VaR -0.05531553, и его видно на графике, однако все же лог-доходность в этом блоке больше, чем VaR. В любом случае, 2 нарушения это все еще в пределах ожидаемого количества.

---

# № 5.2
![[матстат 5.jpg]]